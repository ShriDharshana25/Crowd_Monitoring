{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pncqKc-uoJYK"
      },
      "outputs": [],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Import for Colab\n",
        "\n",
        "# Load YOLOv8 model (you can use yolov8n, yolov8s, yolov8m, etc.)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/crowd_img.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Perform detection on the image\n",
        "results = model(image)\n",
        "\n",
        "# Filter out only 'person' detections (Class 0 in COCO dataset)\n",
        "person_count = 0\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        # Get class ID and confidence\n",
        "        class_id = int(box.cls[0])\n",
        "        if class_id == 0:  # Class '0' is 'person' in YOLO\n",
        "            person_count += 1\n",
        "\n",
        "print(f'Number of people detected: {person_count}')\n",
        "\n",
        "# Optionally display the image with detected people\n",
        "annotated_image = results[0].plot()\n",
        "cv2_imshow(annotated_image)  # Use cv2_imshow for displaying in Colab\n"
      ],
      "metadata": {
        "id": "1s0aaRlxoTTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Video path (Input)\n",
        "video_path = '/content/bbbb.mp4'\n",
        "\n",
        "# Video path (Output)\n",
        "output_video_path = '/content/output_with_detections.mp4'\n",
        "\n",
        "# Initialize video capture and video writer\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Define video codec and create VideoWriter object to save the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)  # Get FPS from the input video\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Real-time processing and saving to output video\n",
        "ppl_threshold = 15  # Overcrowding threshold\n",
        "overcrowding_alert = False  # Flag to track if overcrowding occurs in any frame\n",
        "frame_count = 0  # Frame counter\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: Could not read frame.\")\n",
        "        break  # End of video\n",
        "\n",
        "    # Perform detection using YOLOv8\n",
        "    results = model(frame)\n",
        "\n",
        "    # Filter for 'person' detections and count\n",
        "    try:\n",
        "        person_count = sum(1 for result in results for box in result.boxes if int(box.cls[0]) == 0)\n",
        "    except TypeError as e:\n",
        "        print(\"Error in counting persons:\", e)\n",
        "        person_count = 0  # Fallback in case of error\n",
        "\n",
        "    # Trigger overcrowding alert if people count exceeds the threshold\n",
        "    if person_count > ppl_threshold:\n",
        "        overcrowding_alert = True\n",
        "        print(f\"Overcrowding alert! Frame {frame_count} has {person_count} people.\")\n",
        "\n",
        "    # Annotate the frame with detections\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Save the current annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# Release video resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Output summary\n",
        "if overcrowding_alert:\n",
        "    print(f\"Overcrowding occurred in at least one frame (Threshold: {ppl_threshold} people).\")\n",
        "else:\n",
        "    print(f\"No overcrowding detected (Threshold: {ppl_threshold} people).\")\n",
        "\n",
        "# Display the saved video in the notebook (for Colab or Jupyter environments)\n",
        "video_data = open(output_video_path, 'rb').read()\n",
        "video_encoded = b64encode(video_data).decode()\n",
        "video_tag = f'<video controls src=\"data:video/mp4;base64,{video_encoded}\">'\n",
        "HTML(video_tag)\n"
      ],
      "metadata": {
        "id": "6WkPCUyWIHqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5pt4ERyOSyAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POFAPKN2Sx0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gxivjKqSxlh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}